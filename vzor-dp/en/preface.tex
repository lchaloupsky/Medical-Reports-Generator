\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}

In hospital, inspecting the X-rays and writing corresponding medical reports is a hard work that requires experienced specialized doctors, of which there are not many. A great number of people visit hospitals daily and X-rays are taken for many of them. Automatic interpretation of X-ray images has a great potential to improve health care and it could be particularly helpful to doctors in order to distinguish serious cases from ordinary ones and overall accelerate and improve their work.\\

Automatic generation of radiology reports is a subset of a general problem called Image Captioning, i.e. generation of overall textual captions to input images. Image Captioning is a combination of Natural Language Processing and Computer Vision areas, experiencing a lot of progress in the last years. Most often the Image Captioning problem is solved using Deep Learning techniques. The specificity of this subset is that we do not want to generate just a general caption of the image, but the exact description of all findings contained in the given medical image. There were done multiple studies for this task in other languages but none in the Czech language.\\

Deep learning by its very nature has a wide range of uses in a medical sector as it can often capture complex relations in any kind of data with excellent performance results. Nevertheless, in the medical environment, the accuracy of predictions is crucial in order to determine the final diagnosis. Therefore, we should not consider the models as such as something that is unmistakably true but as an auxiliary tool that should help doctors to examine X-rays.\\

Inasmuch as it is not so challenging to detect fractures on the limbs, this area is less interesting than others which have a variety of diverse possible problems. One of these areas is the chest for which there exist multiple freely accessible datasets containing full textual medical reports. However, all these available datasets have one common downside, they are not in the Czech language. The natural question arises, where do we obtain these much needed data? We have to face and solve this core problem in our thesis.\\

\section*{Goals}
First of all, we will take a closer look at the problem itself. This includes breaking down the problem and analyzing all its parts individually together with presenting possible existing alternatives for each part. \\

The main target of our thesis is to train a neural network for the purpose of generating textual medical reports for X-ray images. An example of our problem can be seen in Figure \hyperref[fig01:ProblemExample]{1.1} for illustration.\\
\newpage

Our first goal is to fine-tune a language model directly for the Czech language. The language model will be specialized directly to medical texts in order to capture the essence of the problem. However, ahead of the medical specialization, we want to fine-tune a general Czech language model. Fine-tuning will be based on the original English GPT-2 model presented in \citet{radford2019language}.\\

Finally, we want to utilize our fine-tuned language models for training neural network models interpreting chest X-rays images and generating corresponding medical textual reports to them in the Czech language. This section also involves the overall data preparation directly for the Czech language. In addition, the training will be done in multiple setups. All possibilities will be evaluated with the purpose of determination of their final performance.\\

\section*{Thesis structure}

In the very first chapter we present a detailed description of our problem. Every aspect of our problem is introduced and all existing solutions or possibilities are discussed with their pros and cons. Moreover, we introduce there some of the important related works.\\

The following chapter is dealing with the design of the solution to our problem, with all reasonings and decisions made. This includes not only the final neural network model but also the language model fine-tuning and data preparation.\\

Technical details about the implemented scripts are described in the third chapter.\\

All experiments done with our models take their part in the fourth chapter, describing all used environments and different setups together with data variants. This section also contains partial results of work related to GPT-2 training.\\

The whole fifth chapter is then dedicated to an extensive evaluation of the experiments carried out in the preceding part.\\

Finally, in the epilog we discuss what we have accomplished in the thesis, what the resulting consequences are, and what the future possibilities are.